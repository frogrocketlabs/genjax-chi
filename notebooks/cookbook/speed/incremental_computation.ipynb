{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Incremental computation via Update\n",
    "subtitle: How to not compute log pdfs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import gen\n",
    "\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing inference with iterative algorithms like MCMC, we often need to make small adjustments to the choice map.\n",
    "\n",
    "For instance, consider the following generative model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def generate_datum(x, prob_outlier, noise, slope, intercept):\n",
    "    b = genjax.flip(prob_outlier) @ \"is_outlier\"\n",
    "    mu, std = jax.lax.cond(\n",
    "        b, lambda _: (0.0, 10.0), lambda _: (slope * x + intercept, noise), None\n",
    "    )\n",
    "    return genjax.normal(mu, std) @ \"y\"\n",
    "\n",
    "\n",
    "@gen\n",
    "def model(xs):\n",
    "    slope = genjax.normal(0.0, 2.0) @ \"slope\"\n",
    "    intercept = genjax.normal(0.0, 2.0) @ \"intercept\"\n",
    "    noise = genjax.gamma(0.0, 1.0) @ \"noise\"\n",
    "    prob_outlier = genjax.beta(1.0, 1.0) @ \"prob_outlier\"\n",
    "    ys = (\n",
    "        generate_datum.vmap(in_axes=(0, None, None, None, None))(\n",
    "            xs, prob_outlier, noise, slope, intercept\n",
    "        )\n",
    "        @ \"data\"\n",
    "    )\n",
    "    return ys\n",
    "\n",
    "\n",
    "def make_observations(ys):\n",
    "    obs = jax.vmap(lambda idx: C[\"data\", idx, \"y\"].set(ys[idx]))(ys)\n",
    "    return obs\n",
    "\n",
    "\n",
    "# TODO: why does it feel a bit like pain to do this in GenJAX? I really want this to be as straightforward as in Gen.jl\n",
    "@gen\n",
    "def is_outlier_proposal(target, i):\n",
    "    prob_outlier = genjax.beta(1.0, 1.0) @ \"prob_outlier\"\n",
    "    return genjax.flip(prob_outlier) @ \"is_outlier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write an inference using MH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iters = 1000\n",
    "\n",
    "\n",
    "def inference_program(key, xs, ys):\n",
    "    constraints = make_observations(ys)\n",
    "    trace, w = model.importance(key, (xs,), constraints)\n",
    "\n",
    "    # TODO:\n",
    "    for i in range(N_iters):\n",
    "        trace, w = model.importance(\n",
    "            key,\n",
    "            (xs,),\n",
    "            constraints,\n",
    "            proposal=is_outlier_proposal,\n",
    "            trace=trace,\n",
    "            weights=w,\n",
    "        )\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to do it using the built-in update and see if there's a speedup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
