{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Parallel Gibbs Sampling\n",
    "subtitle: Surprising ways in which parallelism can be introduced\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genjax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from jax import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have mostly shown how to use GenJAX to run simulations in parallel. Whether it was a generative function on several random keys, on different arguments, they all had a similar flavor of \"simply duplicating particles for inference.\"\n",
    "\n",
    "Here we will show a different kind of example where parallelism can be used for better inference which has a very different flavor: we will do a type of MCMC update to a trace where the move itself benefits from parallel acceleration thanks to the structure of the generative function to which the update is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a simple HMM and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_chain = 100\n",
    "state_size = 300\n",
    "number_runs = 100\n",
    "transition_matrix = jax.random.normal(jax.random.PRNGKey(0), (state_size, state_size))\n",
    "observation_matrix = jax.random.normal(jax.random.PRNGKey(0), (state_size, state_size))\n",
    "latent_variance = jnp.eye(state_size)\n",
    "obs_variance = jnp.eye(state_size)\n",
    "initial_state = jax.random.normal(jax.random.PRNGKey(0), (state_size,))\n",
    "\n",
    "\n",
    "@genjax.gen\n",
    "def hmm_step(x, _):\n",
    "    new_x = (\n",
    "        genjax.mv_normal(jnp.matmul(transition_matrix, x), latent_variance) @ \"new_x\"\n",
    "    )\n",
    "    _ = genjax.mv_normal(jnp.matmul(observation_matrix, new_x), obs_variance) @ \"obs\"\n",
    "    return new_x, None\n",
    "\n",
    "\n",
    "hmm = hmm_step.scan(n=length_chain)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "jitted = jit(hmm.repeat(n=number_runs).simulate)\n",
    "trace = jitted(key, (initial_state, None))\n",
    "# It takes ~1.7s to run 100 runs of the HMM of length 100 where each step has a state size of 300, on M2 CPU.\n",
    "# Strangely enough, all the matrix-vector multiply only take ~0.2s while they perform about 900M operations.\n",
    "# %timeit jitted(subkey, (initial_state, None))\n",
    "trace.get_choices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add observervations and run the default importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm = jax.vmap(\n",
    "    lambda idx: C[idx, \"obs\"].set(idx.astype(float) * jnp.arange(state_size))\n",
    ")(jnp.arange(length_chain))\n",
    "\n",
    "\n",
    "jitted = jit(lambda key: hmm.importance(key, chm, (initial_state, None)))\n",
    "jitted(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_update(trace, parity):\n",
    "    vars_to_update = trace.get_choices()[\"new_x\"]\n",
    "    idx_to_update = jnp.arange(length_chain)[jnp.arange(length_chain) % 2 == parity]\n",
    "    new_vars = jax.ops.index_update(\n",
    "        vars_to_update,\n",
    "        idx_to_update,\n",
    "        jax.random.normal(key, vars_to_update[idx_to_update].shape),\n",
    "    )\n",
    "    return trace.set_choices(new_x=new_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity = False\n",
    "jnp.arange(length_chain)[jnp.arange(length_chain) % 2 == parity]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
