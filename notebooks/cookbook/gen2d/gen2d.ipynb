{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple model for clustering a 2D image into different components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import model_simple_continuous\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy import datasets\n",
    "\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import pretty\n",
    "\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing to sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = datasets.face()\n",
    "H, W, _ = image.shape\n",
    "\n",
    "hypers = model_simple_continuous.Hyperparams(\n",
    "    a_xy=jnp.array([100.0, 100.0]),\n",
    "    b_xy=jnp.array([10000.0, 10000.0]),\n",
    "    mu_xy=jnp.array([H / 2, W / 2]),\n",
    "    a_rgb=jnp.array([25.0, 25.0, 25.0]),\n",
    "    b_rgb=jnp.array([450.0, 450.0, 450.0]),\n",
    "    alpha=1.0,\n",
    "    sigma_xy=jnp.array([1.0, 1.0]),\n",
    "    sigma_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    n_blobs=10,\n",
    "    H=H,\n",
    "    W=W,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "# tr = jax.jit(model_simple_continuous.model.simulate)(subkey, (hypers,))\n",
    "tr = jax.jit(model_simple_continuous.model.simulate)(subkey, (hypers,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do inference via exact block-Gibbs, using the fact that the model is defined using conjugate pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conjugate_update_mvnormal_with_known_cov(\n",
    "#     prior_mean,  # (D,)\n",
    "#     prior_cov,  # (D, D)\n",
    "#     obs_cov,  # (D, D)\n",
    "#     obs,  # (M, D)\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Returns the posterior mean and covariance for the mean\n",
    "#     of a multivariate normal distribution with known covariance.\n",
    "#     That is, given\n",
    "#       mu ~ Normal(prior_mean, prior_cov),\n",
    "#       obs_i ~ Normal(mu, obs_cov) for i = 0, 1, ..., M-1,\n",
    "#     this function returns (post_mean, post_cov) where\n",
    "#       P(mu | obs) = Normal(post_mean, post_cov).\n",
    "#     \"\"\"\n",
    "#     M = obs.shape[0]\n",
    "#     post_cov = jnp.linalg.inv(jnp.linalg.inv(prior_cov) + M * jnp.linalg.inv(obs_cov))\n",
    "#     obsmean = jnp.sum(obs) / M\n",
    "#     post_mean = post_cov @ (\n",
    "#         jnp.linalg.inv(prior_cov) @ prior_mean + M * jnp.linalg.inv(obs_cov) @ obsmean\n",
    "#     )\n",
    "#     return jnp.where(M > 0, post_mean, prior_mean), jnp.where(\n",
    "#         M > 0, post_cov, prior_cov\n",
    "#     )\n",
    "\n",
    "\n",
    "# def dirichlet_categorical_update(key, associations, n_clusters, alpha):\n",
    "#     \"\"\"Returns (categorical_vector, metadata_dict).\"\"\"\n",
    "\n",
    "#     def get_assoc_count(cluster_idx):\n",
    "#         masked_relevant_datapoint_indices = tiling.relevant_datapoints_for_blob(\n",
    "#             cluster_idx\n",
    "#         )\n",
    "#         relevant_associations = associations[masked_relevant_datapoint_indices.value]\n",
    "#         return jnp.sum(\n",
    "#             jnp.logical_and(\n",
    "#                 masked_relevant_datapoint_indices.flag,\n",
    "#                 relevant_associations == cluster_idx,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     assoc_counts = jax.vmap(get_assoc_count)(jnp.arange(n_clusters))\n",
    "#     prior_alpha = alpha\n",
    "#     post_alpha = prior_alpha + assoc_counts\n",
    "#     return dirichlet(post_alpha)(key), {}\n",
    "\n",
    "\n",
    "# def conjugate_dirichlet_categorical(\n",
    "#     key, associations, n_clusters, alpha, λ=model_simple_continuous.GAMMA_RATE_PARAMETER\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Conjugate update for the case where we have\n",
    "#         X_i ~ Gamma(alpha_i / n, lambda) for i = 1, 2, ..., n;\n",
    "#         X_0 := sum_i X_i\n",
    "#         p := [X_1, X_2, ..., X_n] / X_0\n",
    "#         Y_i ~ Categorical(p) for i = 1, 2, ..., m.\n",
    "\n",
    "#     Here, `n_clusters` is `n`, `associations` is `Y`,\n",
    "#     and `alpha_vec_for_gamma_distributions[i-1]` is `alpha_i`.\n",
    "\n",
    "#     Returns (mixture_weights, metadata), where `mixture_weights`\n",
    "#     is the same thing as the vector `[X_1, X_2, ..., X_n]`.\n",
    "#     \"\"\"\n",
    "#     ## Derivation of this update:\n",
    "#     # With notation as the above, it turns out\n",
    "#     # X_0 ~ Gamma(alpha.sum(), lambda),\n",
    "#     # p ~ Dirichlet(alpha_1, alpha_2, ..., alpha_n),\n",
    "#     # and X_0 and p are independent.\n",
    "#     # Thus, the posterior on (X_0, p) is\n",
    "#     # p ~ dirichlet_categorical_posterior(alpha, n, assoc_counts);\n",
    "#     # X_0 ~ gamma(alpha.sum(), lambda). # Ie. same as the prior.\n",
    "#     k1, k2 = jax.random.split(key)\n",
    "#     posterior_pvec, _ = dirichlet_categorical_update(\n",
    "#         k1, associations, n_clusters, alpha\n",
    "#     )\n",
    "#     total = gamma(alpha.sum(), λ)(k2)\n",
    "#     return posterior_pvec * total, {}\n",
    "\n",
    "\n",
    "# # one option in the mean time is to replace inverse_gamma in the model by a categorical with 64 values.\n",
    "# def conjugate_update_mean_normal_inverse_gamma():\n",
    "#     return None\n",
    "\n",
    "\n",
    "def update_xy_mean(key, tr):\n",
    "    # datapoint_indexes = trace.get_choices()[\"likelihood_model\", \"blob_idx\"]\n",
    "    # datapoints = trace.get_choices()[\"likelihood_model\", \"xy\"]\n",
    "    # n_clusters = trace.get_args().n_blobs\n",
    "    # current_means = trace.get_choices()[\"blob_model\", \"xy_mean\"] # shape (N,2)\n",
    "\n",
    "    # # Count number of points per cluster\n",
    "    # category_counts = jnp.bincount(\n",
    "    #     datapoint_indexes,\n",
    "    #     length=n_clusters,\n",
    "    #     minlength=n_clusters,\n",
    "    # )\n",
    "\n",
    "    # # Will contain some NaN due to clusters having no datapoint\n",
    "    # cluster_means = (\n",
    "    #     jax.vmap(\n",
    "    #         lambda i: jnp.sum(jnp.where(datapoint_indexes == i, datapoints, 0)),\n",
    "    #         in_axes=(0),\n",
    "    #         out_axes=(0),\n",
    "    #     )(jnp.arange(n_clusters))\n",
    "    #     / category_counts\n",
    "    # )\n",
    "\n",
    "    # # Conjugate update for Normal-iid-Normal distribution\n",
    "    # posterior_means = (\n",
    "    #     PRIOR_VARIANCE\n",
    "    #     / (PRIOR_VARIANCE + OBS_VARIANCE / category_counts)\n",
    "    #     * cluster_means\n",
    "    #     + (OBS_VARIANCE / category_counts)\n",
    "    #     / (PRIOR_VARIANCE + OBS_VARIANCE / category_counts)\n",
    "    #     * PRIOR_MEAN\n",
    "    # )\n",
    "\n",
    "    # posterior_variances = 1 / (1 / PRIOR_VARIANCE + category_counts / OBS_VARIANCE)\n",
    "\n",
    "    # # Gibbs resampling of cluster means\n",
    "    # key, subkey = jax.random.split(key)\n",
    "    # new_means = (\n",
    "    #     generate_cluster.vmap()\n",
    "    #     .simulate(key, (posterior_means, posterior_variances))\n",
    "    #     .get_choices()[\"mean\"]\n",
    "    # )\n",
    "\n",
    "    # # Remove the sampled Nan due to clusters having no datapoint and pick previous mean in that case, i.e. no Gibbs update for them\n",
    "    # chosen_means = jnp.where(category_counts == 0, current_means, new_means)\n",
    "\n",
    "    # argdiffs = genjax.Diff.no_change(trace.args)\n",
    "    # new_trace, _, _, _ = trace.update(\n",
    "    #     subkey, C[\"clusters\", \"mean\"].set(chosen_means), argdiffs\n",
    "    # )\n",
    "\n",
    "    # return new_trace\n",
    "    return tr\n",
    "\n",
    "\n",
    "def update_xy_sigma(key, tr):\n",
    "    return tr\n",
    "\n",
    "\n",
    "def update_rgb_mean(key, tr):\n",
    "    return tr\n",
    "\n",
    "\n",
    "def update_rgb_sigma(key, tr):\n",
    "    return tr\n",
    "\n",
    "\n",
    "def update_cluster_assignment(key, tr):\n",
    "    return tr\n",
    "\n",
    "\n",
    "def update_mixture_weight(key, tr):\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT STEPS: add one by one the Gibbs updates and test them individually\n",
    "- update xy mean\n",
    "- update rgb mean\n",
    "- update cluster assignment\n",
    "- update cluster weight\n",
    "- update sigma_xy\n",
    "- update sigma_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 100\n",
    "RECORD = True\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def infer(image, hypers):\n",
    "    key = jax.random.key(32421)\n",
    "\n",
    "    # Image pre-processing\n",
    "    H = hypers.H\n",
    "    W = hypers.W\n",
    "    flattened_image = jnp.concatenate(\n",
    "        (jnp.indices((H, W)).reshape(H * W, 2), image.reshape(H * W, 3)), axis=1\n",
    "    )\n",
    "    xy, rgb = flattened_image[:, :2], flattened_image[:, 2:]\n",
    "\n",
    "    # Setup for better initial trace\n",
    "    n_blobs = hypers.n_blobs\n",
    "    obs = C[\"likelihood_model\", \"xy\"].set(xy) ^ C[\"likelihood_model\", \"rgb\"].set(rgb)\n",
    "    initial_weights = C[\"blob_model\", \"mixture_weight\"].set(jnp.ones(n_blobs) / n_blobs)\n",
    "    constraints = obs | initial_weights\n",
    "\n",
    "    # Sample an initial trace\n",
    "    key, subkey = jax.random.split(key)\n",
    "    args = (hypers,)\n",
    "    tr, _ = jax.jit(model_simple_continuous.model.importance)(subkey, constraints, args)\n",
    "\n",
    "    # Record info for plotting and debugging purposes\n",
    "    if RECORD:\n",
    "        all_posterior_xy_means = [tr.get_choices()[\"blob_model\", \"xy_mean\"]]\n",
    "        all_posterior_xy_variances = [tr.get_choices()[\"blob_model\", \"sigma_xy\"]]\n",
    "        all_posterior_rgb_means = [tr.get_choices()[\"blob_model\", \"rgb_mean\"]]\n",
    "        all_posterior_rgb_variances = [tr.get_choices()[\"blob_model\", \"sigma_rgb\"]]\n",
    "        all_cluster_assignment = [tr.get_choices()[\"likelihood_model\", \"blob_idx\"]]\n",
    "        all_posterior_weights = [tr.get_choices()[\"blob_model\", \"mixture_weight\"]]\n",
    "\n",
    "        if DEBUG:\n",
    "            jax.debug.print(\"Initial means: {v}\", v=all_posterior_xy_means[0])\n",
    "            jax.debug.print(\"Initial weights: {v}\", v=all_posterior_weights[0])\n",
    "\n",
    "        # Main inference loop\n",
    "        for _ in range(N_ITER):\n",
    "            # Gibbs update on `(\"blob_model\", \"xy_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_xy_mean)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"xy_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_xy\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_xy_sigma)(subkey, tr)\n",
    "            all_posterior_xy_variances.append(\n",
    "                tr.get_choices()[\"blob_model\", \"sigma_xy\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"rgb_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_rgb_mean)(subkey, tr)\n",
    "            all_posterior_rgb_means.append(tr.get_choices()[\"blob_model\", \"rgb_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_rgb\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_rgb_sigma)(subkey, tr)\n",
    "            all_posterior_rgb_variances.append(\n",
    "                tr.get_choices()[\"blob_model\", \"sigma_rgb\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"likelihood_model\", \"blob_idx\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_cluster_assignment)(subkey, tr)\n",
    "            all_cluster_assignment.append(\n",
    "                tr.get_choices()[\"likelihood_model\", \"blob_idx\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"mixture_weight\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_mixture_weight)(subkey, tr)\n",
    "            all_posterior_weights.append(\n",
    "                tr.get_choices()[\"blob_model\", \"mixture_weight\"]\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            all_posterior_xy_means,\n",
    "            all_posterior_xy_variances,\n",
    "            all_posterior_rgb_means,\n",
    "            all_posterior_rgb_variances,\n",
    "            all_posterior_weights,\n",
    "            all_cluster_assignment,\n",
    "            tr,\n",
    "        )\n",
    "\n",
    "\n",
    "image = datasets.face()\n",
    "hypers = model_simple_continuous.Hyperparams(\n",
    "    a_xy=jnp.array([100.0, 100.0]),\n",
    "    b_xy=jnp.array([10000.0, 10000.0]),\n",
    "    mu_xy=jnp.array([H / 2, W / 2]),\n",
    "    a_rgb=jnp.array([25.0, 25.0, 25.0]),\n",
    "    b_rgb=jnp.array([450.0, 450.0, 450.0]),\n",
    "    alpha=1.0,\n",
    "    sigma_xy=jnp.array([1.0, 1.0]),\n",
    "    sigma_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    n_blobs=10,\n",
    "    H=H,\n",
    "    W=W,\n",
    ")\n",
    "\n",
    "(\n",
    "    all_posterior_xy_means,\n",
    "    all_posterior_xy_variances,\n",
    "    all_posterior_rgb_means,\n",
    "    all_posterior_rgb_variances,\n",
    "    all_posterior_weights,\n",
    "    all_cluster_assignment,\n",
    "    tr,\n",
    ") = jax.jit(infer)(image, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 10\n",
    "\n",
    "\n",
    "# Function to create plot for a given index\n",
    "def create_plot(idx):\n",
    "    image = datasets.face()\n",
    "\n",
    "    posterior_xy_means = all_posterior_xy_means[idx]\n",
    "    posterior_xy_variances = all_posterior_xy_variances[idx]\n",
    "    posterior_rgb_means = all_posterior_rgb_means[idx]\n",
    "    # posterior_rgb_variances = all_posterior_rgb_variances[idx]\n",
    "    posterior_weights = all_posterior_weights[idx]\n",
    "    cluster_assignment = all_cluster_assignment[idx].reshape(H, W)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5), facecolor=\"white\")\n",
    "    ax.set_facecolor(\"white\")\n",
    "\n",
    "    ax.imshow(image, alpha=0.4, extent=[0, image.shape[1], image.shape[0], 0])\n",
    "    ax.set_xlim(0, image.shape[1])\n",
    "    ax.set_ylim(image.shape[0], 0)\n",
    "\n",
    "    # Create coordinate arrays for all points\n",
    "    y_coords, x_coords = jnp.mgrid[0:H, 0:W]\n",
    "    points = jnp.stack([x_coords.flatten(), y_coords.flatten()], axis=1)\n",
    "\n",
    "    # Plot datapoints colored by cluster assignment and posterior means together\n",
    "    for i in range(len(posterior_xy_means)):\n",
    "        # Only plot points assigned to this cluster\n",
    "        mask = cluster_assignment.flatten() == i\n",
    "        n_points = jnp.sum(mask)\n",
    "\n",
    "        if not jnp.any(mask):  # Skip if no points assigned to this cluster\n",
    "            continue\n",
    "\n",
    "        cluster_color = tuple(\n",
    "            float(x) for x in (posterior_rgb_means[i].astype(float) / 255.0)\n",
    "        )\n",
    "\n",
    "        # Plot only 1/50 of the actual data points for this cluster for legibility\n",
    "        points_in_cluster = points[mask]\n",
    "        subsample_idx = jnp.arange(0, len(points_in_cluster), 50)\n",
    "        points_subsampled = points_in_cluster[subsample_idx]\n",
    "        ax.scatter(\n",
    "            points_subsampled[:, 0],\n",
    "            points_subsampled[:, 1],\n",
    "            c=[cluster_color],\n",
    "            marker=\".\",\n",
    "            s=10,\n",
    "            alpha=0.25,\n",
    "        )\n",
    "\n",
    "        # Plot posterior means with size proportional to weights\n",
    "        weight = float(posterior_weights[i])\n",
    "        ax.scatter(\n",
    "            float(posterior_xy_means[i, 0]),\n",
    "            float(posterior_xy_means[i, 1]),\n",
    "            c=[cluster_color],\n",
    "            marker=\"*\",\n",
    "            s=150 + weight * 800,  #\n",
    "            alpha=1,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1,\n",
    "            label=f\"Cluster {i + 1} (Prob: {weight:.6f}, Points: {int(n_points)})\",\n",
    "        )\n",
    "\n",
    "        # Plot standard deviation of the Gaussian means as ellipses\n",
    "        std_x = float(jnp.sqrt(posterior_xy_variances[i, 0]))\n",
    "        std_y = float(jnp.sqrt(posterior_xy_variances[i, 1]))\n",
    "\n",
    "        ellipse = Ellipse(\n",
    "            (\n",
    "                float(posterior_xy_means[i, 0]),\n",
    "                float(posterior_xy_means[i, 1]),\n",
    "            ),\n",
    "            width=20 * std_x,\n",
    "            height=20 * std_y,\n",
    "            alpha=0.5,\n",
    "            color=cluster_color,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "        ax.add_patch(ellipse)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.15),\n",
    "        ncol=3,\n",
    "        facecolor=\"white\",\n",
    "        edgecolor=\"black\",\n",
    "        framealpha=1,\n",
    "    )\n",
    "    ax.set_title(f\"Iteration {idx}\", pad=20, fontsize=12, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create animation\n",
    "frames = []\n",
    "for i in range(NUM_FRAMES):\n",
    "    fig = create_plot(int(N_ITER / NUM_FRAMES * i))\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=\"uint8\")\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Create animation from frames\n",
    "fig = plt.figure(figsize=(12, 5), facecolor=\"white\")\n",
    "from matplotlib import animation\n",
    "\n",
    "ani = animation.ArtistAnimation(\n",
    "    fig,\n",
    "    [[plt.imshow(frame)] for frame in frames],\n",
    "    interval=200,\n",
    "    blit=True,\n",
    ")\n",
    "\n",
    "# Save animation as GIF\n",
    "imageio.mimsave(\"dirichlet_mixture_animation.gif\", frames, fps=15)\n",
    "\n",
    "# Display animation in notebook\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
