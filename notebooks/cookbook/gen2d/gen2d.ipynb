{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple model for clustering a 2D image into different components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import model_simple_continuous\n",
    "from scipy import misc\n",
    "\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import pretty\n",
    "\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing to sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = misc.face()\n",
    "H, W, _ = image.shape\n",
    "\n",
    "hypers = model_simple_continuous.Hyperparams(\n",
    "    a_xy=jnp.array([1.0, 1.0]),\n",
    "    b_xy=jnp.array([1.0, 1.0]),\n",
    "    mu_xy=jnp.array([0.0, 0.0]),\n",
    "    a_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    b_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    alpha=1.0,\n",
    "    sigma_xy=jnp.array([1.0, 1.0]),\n",
    "    sigma_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    n_blobs=10,\n",
    "    H=H,\n",
    "    W=W,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "# tr = jax.jit(model_simple_continuous.model.simulate)(subkey, (hypers,))\n",
    "tr = jax.jit(model_simple_continuous.model.simulate)(subkey, (hypers,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do inference via exact block-Gibbs, using the fact that the model is defined using conjugate pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conjugate_update_mvnormal_with_known_cov(\n",
    "#     prior_mean,  # (D,)\n",
    "#     prior_cov,  # (D, D)\n",
    "#     obs_cov,  # (D, D)\n",
    "#     obs,  # (M, D)\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Returns the posterior mean and covariance for the mean\n",
    "#     of a multivariate normal distribution with known covariance.\n",
    "#     That is, given\n",
    "#       mu ~ Normal(prior_mean, prior_cov),\n",
    "#       obs_i ~ Normal(mu, obs_cov) for i = 0, 1, ..., M-1,\n",
    "#     this function returns (post_mean, post_cov) where\n",
    "#       P(mu | obs) = Normal(post_mean, post_cov).\n",
    "#     \"\"\"\n",
    "#     M = obs.shape[0]\n",
    "#     post_cov = jnp.linalg.inv(jnp.linalg.inv(prior_cov) + M * jnp.linalg.inv(obs_cov))\n",
    "#     obsmean = jnp.sum(obs) / M\n",
    "#     post_mean = post_cov @ (\n",
    "#         jnp.linalg.inv(prior_cov) @ prior_mean + M * jnp.linalg.inv(obs_cov) @ obsmean\n",
    "#     )\n",
    "#     return jnp.where(M > 0, post_mean, prior_mean), jnp.where(\n",
    "#         M > 0, post_cov, prior_cov\n",
    "#     )\n",
    "\n",
    "\n",
    "# def dirichlet_categorical_update(key, associations, n_clusters, alpha):\n",
    "#     \"\"\"Returns (categorical_vector, metadata_dict).\"\"\"\n",
    "\n",
    "#     def get_assoc_count(cluster_idx):\n",
    "#         masked_relevant_datapoint_indices = tiling.relevant_datapoints_for_blob(\n",
    "#             cluster_idx\n",
    "#         )\n",
    "#         relevant_associations = associations[masked_relevant_datapoint_indices.value]\n",
    "#         return jnp.sum(\n",
    "#             jnp.logical_and(\n",
    "#                 masked_relevant_datapoint_indices.flag,\n",
    "#                 relevant_associations == cluster_idx,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     assoc_counts = jax.vmap(get_assoc_count)(jnp.arange(n_clusters))\n",
    "#     prior_alpha = alpha\n",
    "#     post_alpha = prior_alpha + assoc_counts\n",
    "#     return dirichlet(post_alpha)(key), {}\n",
    "\n",
    "\n",
    "# def conjugate_dirichlet_categorical(\n",
    "#     key, associations, n_clusters, alpha, λ=model_simple_continuous.GAMMA_RATE_PARAMETER\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Conjugate update for the case where we have\n",
    "#         X_i ~ Gamma(alpha_i / n, lambda) for i = 1, 2, ..., n;\n",
    "#         X_0 := sum_i X_i\n",
    "#         p := [X_1, X_2, ..., X_n] / X_0\n",
    "#         Y_i ~ Categorical(p) for i = 1, 2, ..., m.\n",
    "\n",
    "#     Here, `n_clusters` is `n`, `associations` is `Y`,\n",
    "#     and `alpha_vec_for_gamma_distributions[i-1]` is `alpha_i`.\n",
    "\n",
    "#     Returns (mixture_weights, metadata), where `mixture_weights`\n",
    "#     is the same thing as the vector `[X_1, X_2, ..., X_n]`.\n",
    "#     \"\"\"\n",
    "#     ## Derivation of this update:\n",
    "#     # With notation as the above, it turns out\n",
    "#     # X_0 ~ Gamma(alpha.sum(), lambda),\n",
    "#     # p ~ Dirichlet(alpha_1, alpha_2, ..., alpha_n),\n",
    "#     # and X_0 and p are independent.\n",
    "#     # Thus, the posterior on (X_0, p) is\n",
    "#     # p ~ dirichlet_categorical_posterior(alpha, n, assoc_counts);\n",
    "#     # X_0 ~ gamma(alpha.sum(), lambda). # Ie. same as the prior.\n",
    "#     k1, k2 = jax.random.split(key)\n",
    "#     posterior_pvec, _ = dirichlet_categorical_update(\n",
    "#         k1, associations, n_clusters, alpha\n",
    "#     )\n",
    "#     total = gamma(alpha.sum(), λ)(k2)\n",
    "#     return posterior_pvec * total, {}\n",
    "\n",
    "\n",
    "# # one option in the mean time is to replace inverse_gamma in the model by a categorical with 64 values.\n",
    "# def conjugate_update_mean_normal_inverse_gamma():\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def conjugate_update_sigma_normal_inverse_gamma():\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def conjugate_discrete_enumeration():\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def update_xy_mean(xy_mean, xy_mean_blanket):\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def update_xy_sigma(xy_sigma, xy_sigma_blanket):\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def update_rgb_mean(rgb_mean, rgb_mean_blanket):\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def update_rgb_sigma(rgb_sigma, rgb_sigma_blanket):\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### exact inference on discretized model\n",
    "### exact Gibbs move on discretized model\n",
    "### exact Gibbs for continuous model\n",
    "### test exact Gibbs\n",
    "### update for cont model\n",
    "\n",
    "### What do I want?\n",
    "# Ideally, model.exact_infer(key, obs, args)\n",
    "# as well as the generality for sub_model.exact_infer(key, obs, args)\n",
    "# something cool would be an automatic plotting of the BayesNet of the model.\n",
    "\n",
    "### Math for complexity of exact inference on this model:\n",
    "# model:\n",
    "# P(latents | image, hypers)\n",
    "# = P(latents, image | hypers) / P(image)\n",
    "# = P(xy_mean, rgb_mean, mixture_weight | hypers)\n",
    "# * P(blob_idx | mixture_weight)\n",
    "# * P(xy | xy_mean rgb, blob_idx, hypers)\n",
    "# * P( rgb | rgb_mean rgb, blob_idx, hypers)  / P(image) = sum_{xy_mean, rgb_mean, mixture_weight, blob_idx} P(latents, image | hypers)\n",
    "# size of the sum: |xy_mean| * | rgb_mean| * |mixture_weight| * |blob_idx| * |n_blobs | * | image |\n",
    "# = 64**2 * 64 ** 3 * 64 * 100 * 10 ** 6\n",
    "# ~ 7. 10^18, without counting the cost of each eval nor ranging over a set of hyper parameters.\n",
    "# L4 GPU can do 30 * 10^12 flop per sec -> problem.\n",
    "\n",
    "\n",
    "### However, that's the naive version not tacking the Markov blanket and conditional independence into account. E.g. in HMM using dynamic programming\n",
    "# we can reduce the complexity from exponential in the length of the chain to linear. The argument there is as follows for a chain of length 3.\n",
    "# P(x1, x2, x2 | y1, y2, y3)\n",
    "# = P(x1 | y1) . P(x2 | x1, y2). P(x3 | x2, y3)\n",
    "# = (P(x1 , y1) / \\sum_{x1} P(x1, y1))\n",
    "# . (P(x1, x2, y2) / \\sum_{x1, x2} P(x1, x2, y2))\n",
    "# . (...)\n",
    "# =\n",
    "\n",
    "# NOTES:\n",
    "# - I may want to keep the distribution for observed data continuous to simplify and avoid unnecessary 0 likelihood.\n",
    "# - can compress the image to make inference faster, and one can even do SMC from low res to high res.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT STEPS:\n",
    "1) minimal visualization of the trace over time\n",
    "2) inference loop with identity rewrite for Gibbs updates\n",
    "3) add one by one the Gibbs updates and test them individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 100\n",
    "RECORD = True\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def identity_update(key, tr):\n",
    "    return tr\n",
    "\n",
    "\n",
    "def infer(image, hypers):\n",
    "    key = jax.random.key(32421)\n",
    "\n",
    "    # Image pre-processing\n",
    "    H = hypers.H\n",
    "    W = hypers.W\n",
    "    flattened_image = jnp.concatenate(\n",
    "        (jnp.indices((H, W)).reshape(H * W, 2), image.reshape(H * W, 3)), axis=1\n",
    "    )\n",
    "    xy, rgb = flattened_image[:, :2], flattened_image[:, 2:]\n",
    "\n",
    "    # Setup for better initial trace\n",
    "    n_blobs = hypers.n_blobs\n",
    "    obs = C[\"likelihood_model\", \"xy\"].set(xy) ^ C[\"likelihood_model\", \"rgb\"].set(rgb)\n",
    "    initial_weights = C[\"blob_model\", \"mixture_weight\"].set(jnp.ones(n_blobs) / n_blobs)\n",
    "    constraints = obs | initial_weights\n",
    "\n",
    "    # Sample an initial trace\n",
    "    key, subkey = jax.random.split(key)\n",
    "    args = (hypers,)\n",
    "    tr, _ = jax.jit(model_simple_continuous.model.importance)(subkey, constraints, args)\n",
    "\n",
    "    # Record info for plotting and debugging purposes\n",
    "    if RECORD:\n",
    "        # TODO:\n",
    "        all_posterior_xy_means = [tr.get_choices()[\"blob_model\", \"xy_mean\"]]\n",
    "        all_posterior_xy_variances = [tr.get_choices()[\"blob_model\", \"sigma_xy\"]]\n",
    "        all_posterior_rgb_means = [tr.get_choices()[\"blob_model\", \"rgb_mean\"]]\n",
    "        all_posterior_rgb_variances = [tr.get_choices()[\"blob_model\", \"sigma_rgb\"]]\n",
    "        all_cluster_assignment = [tr.get_choices()[\"likelihood_model\", \"blob_idx\"]]\n",
    "        all_posterior_weights = [tr.get_choices()[\"blob_model\", \"mixture_weight\"]]\n",
    "\n",
    "        if DEBUG:\n",
    "            jax.debug.print(\"Initial means: {v}\", v=all_posterior_xy_means[0])\n",
    "            jax.debug.print(\"Initial weights: {v}\", v=all_posterior_weights[0])\n",
    "\n",
    "        # Main inference loop\n",
    "        for _ in range(N_ITER):\n",
    "            # Gibbs update on `(\"blob_model\", \"xy_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"xy_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_xy\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"sigma_xy\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"rgb_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"rgb_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_rgb\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"sigma_rgb\"])\n",
    "\n",
    "            # Gibbs update on `(\"likelihood_model\", \"blob_idx\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_cluster_assignment.append(\n",
    "                tr.get_choices()[\"likelihood_model\", \"blob_idx\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"mixture_weight\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(identity_update)(subkey, tr)\n",
    "            all_posterior_weights.append(\n",
    "                tr.get_choices()[\"blob_model\", \"mixture_weight\"]\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            all_posterior_xy_means,\n",
    "            all_posterior_xy_variances,\n",
    "            all_posterior_rgb_means,\n",
    "            all_posterior_rgb_variances,\n",
    "            all_posterior_weights,\n",
    "            all_cluster_assignment,\n",
    "            tr,\n",
    "        )\n",
    "\n",
    "\n",
    "(\n",
    "    all_posterior_xy_means,\n",
    "    all_posterior_xy_variances,\n",
    "    all_posterior_rgb_means,\n",
    "    all_posterior_rgb_variances,\n",
    "    all_posterior_weights,\n",
    "    all_cluster_assignment,\n",
    "    tr,\n",
    ") = infer(image, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
