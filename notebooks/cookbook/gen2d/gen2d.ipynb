{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple model for clustering a 2D image into different components.\n",
    "We recommend running it on a GPU, especially if N_ITER > 10 or N_BLOBS > 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import animation\n",
    "import gibbs_updates\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import model_simple_continuous\n",
    "from scipy import datasets\n",
    "\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import pretty\n",
    "from genjax._src.core.generative.choice_map import ChoiceMap\n",
    "\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 5\n",
    "RECORD = True\n",
    "DEBUG = False\n",
    "# Helper to desactivate some Gibbs move and help debug\n",
    "TRIVIAL = [False, False, False, False, True, False]\n",
    "\n",
    "image = datasets.face()\n",
    "H, W, _ = image.shape\n",
    "\n",
    "# # Load and convert image\n",
    "# image = mpimg.imread(\"image (4).png\")[::2, ::2]\n",
    "# H, W, _ = image.shape\n",
    "\n",
    "N_BLOBS = 81  # needs to be a square number for now\n",
    "A_XY = jnp.array([100.0, 100.0])\n",
    "B_XY = jnp.array([10000.0, 10000.0])\n",
    "MU_XY = jnp.array([H / 2, W / 2])\n",
    "A_RGB = jnp.array([25.0, 25.0, 25.0])\n",
    "B_RGB = jnp.array([450.0, 450.0, 450.0])\n",
    "ALPHA: float = 1.0\n",
    "SIGMA_XY = jnp.array([\n",
    "    H / jnp.sqrt(N_BLOBS),\n",
    "    W / jnp.sqrt(N_BLOBS),\n",
    "])  # so that the initial grid of blobs roughly covers the image\n",
    "SIGMA_RGB = jnp.array([10.0, 10.0, 10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing to sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = model_simple_continuous.Hyperparams(\n",
    "    a_xy=A_XY,\n",
    "    b_xy=B_XY,\n",
    "    mu_xy=MU_XY,\n",
    "    a_rgb=A_RGB,\n",
    "    b_rgb=B_RGB,\n",
    "    alpha=ALPHA,\n",
    "    sigma_xy=SIGMA_XY,\n",
    "    sigma_rgb=SIGMA_RGB,\n",
    "    n_blobs=N_BLOBS,\n",
    "    H=H,\n",
    "    W=W,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "# tr = jax.jit(model_simple_continuous.model.simulate)(subkey, (hypers,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do inference via exact block-Gibbs, using the fact that the model is defined using conjugate pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT IMMEDIATE STEPS: \n",
    "- add one by one the Gibbs updates and test them individually\n",
    "  - improve performance and try on GPU\n",
    "  - update sigma_xy\n",
    "  - update sigma_rgb\n",
    "  - there's a few weird clusters on the animation\n",
    "  - ask George how to recover when some cluster has no points or no weight\n",
    "  - infer hyperparams using exact Gibbs\n",
    "\n",
    "NEXT BIGGER STEPS:\n",
    "- add hyperclustering to recover proto-objects\n",
    "- do real time inference on videos\n",
    "- model attention (bias number of gaussians in a chosen region by artificially likelihood to matter more, e.g. duplicating points in that region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id(key, trace):\n",
    "    return trace\n",
    "\n",
    "\n",
    "def infer(image, hypers):\n",
    "    key = jax.random.key(32421)\n",
    "\n",
    "    # Image pre-processing\n",
    "    H = hypers.H\n",
    "    W = hypers.W\n",
    "    y_coords, x_coords = jnp.indices((H, W))\n",
    "    coords = jnp.stack([x_coords, y_coords], axis=-1)  # Create (x,y) pairs\n",
    "    flattened_image = jnp.concatenate(\n",
    "        (coords.reshape(H * W, 2), image.reshape(H * W, 3)), axis=1\n",
    "    )\n",
    "    xy, rgb = flattened_image[:, :2], flattened_image[:, 2:]\n",
    "\n",
    "    # Setup for better initial trace\n",
    "    n_blobs = hypers.n_blobs\n",
    "    obs: ChoiceMap = C[\"likelihood_model\", \"xy\"].set(xy) | C[\n",
    "        \"likelihood_model\", \"rgb\"\n",
    "    ].set(rgb)\n",
    "    initial_weights = C[\"blob_model\", \"mixture_weight\"].set(jnp.ones(n_blobs) / n_blobs)\n",
    "    grid_of_xy_means = jnp.array([\n",
    "        [\n",
    "            (i % jnp.array(jnp.sqrt(n_blobs), dtype=jnp.int32) + 0.5)\n",
    "            * (W / jnp.sqrt(n_blobs)),\n",
    "            (i // jnp.array(jnp.sqrt(n_blobs), dtype=jnp.int32) + 0.5)\n",
    "            * (H / jnp.sqrt(n_blobs)),\n",
    "        ]\n",
    "        for i in range(n_blobs)\n",
    "    ])\n",
    "    initial_cluster_xy_mean = C[\"blob_model\", \"xy_mean\"].set(grid_of_xy_means)\n",
    "    grid_of_points = jnp.argmin(\n",
    "        jnp.sum((xy[:, None, :] - grid_of_xy_means[None, :, :]) ** 2, axis=2), axis=1\n",
    "    )\n",
    "    initial_cluster_assignment = C[\"likelihood_model\", \"blob_idx\"].set(grid_of_points)\n",
    "    constraints = (\n",
    "        obs | initial_weights | initial_cluster_xy_mean | initial_cluster_assignment\n",
    "    )\n",
    "\n",
    "    # Sample an initial trace\n",
    "    key, subkey = jax.random.split(key)\n",
    "    args = (hypers,)\n",
    "    tr, _ = jax.jit(model_simple_continuous.model.importance)(subkey, constraints, args)\n",
    "\n",
    "    # Record info for plotting and debugging purposes\n",
    "    if RECORD:\n",
    "        all_posterior_xy_means: list[Any] = [tr.get_choices()[\"blob_model\", \"xy_mean\"]]\n",
    "        all_posterior_xy_variances = [tr.get_choices()[\"blob_model\", \"sigma_xy\"]]\n",
    "        all_posterior_rgb_means = [tr.get_choices()[\"blob_model\", \"rgb_mean\"]]\n",
    "        all_posterior_rgb_variances = [tr.get_choices()[\"blob_model\", \"sigma_rgb\"]]\n",
    "        all_cluster_assignment = [tr.get_choices()[\"likelihood_model\", \"blob_idx\"]]\n",
    "        all_posterior_weights = [tr.get_choices()[\"blob_model\", \"mixture_weight\"]]\n",
    "\n",
    "        if DEBUG:\n",
    "            jax.debug.print(\"Initial means: {v}\", v=all_posterior_xy_means[0])\n",
    "            jax.debug.print(\"Initial weights: {v}\", v=all_posterior_weights[0])\n",
    "\n",
    "        # Main inference loop\n",
    "        for _ in range(N_ITER):\n",
    "            # Gibbs update on `(\"likelihood_model\", \"blob_idx\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[0]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_cluster_assignment)(subkey, tr)\n",
    "            all_cluster_assignment.append(\n",
    "                tr.get_choices()[\"likelihood_model\", \"blob_idx\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"xy_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[1]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_xy_mean)(subkey, tr)\n",
    "            all_posterior_xy_means.append(tr.get_choices()[\"blob_model\", \"xy_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_xy\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[2]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_xy_sigma)(subkey, tr)\n",
    "            all_posterior_xy_variances.append(\n",
    "                tr.get_choices()[\"blob_model\", \"sigma_xy\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"rgb_mean\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[3]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_rgb_mean)(subkey, tr)\n",
    "            all_posterior_rgb_means.append(tr.get_choices()[\"blob_model\", \"rgb_mean\"])\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"sigma_rgb\", i)` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[4]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_rgb_sigma)(subkey, tr)\n",
    "            all_posterior_rgb_variances.append(\n",
    "                tr.get_choices()[\"blob_model\", \"sigma_rgb\"]\n",
    "            )\n",
    "\n",
    "            # Gibbs update on `(\"blob_model\", \"mixture_weight\", i)` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            if TRIVIAL[5]:\n",
    "                tr = id(key, tr)\n",
    "            else:\n",
    "                tr = jax.jit(gibbs_updates.update_mixture_weight)(subkey, tr)\n",
    "            all_posterior_weights.append(\n",
    "                tr.get_choices()[\"blob_model\", \"mixture_weight\"]\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            all_posterior_xy_means,\n",
    "            all_posterior_xy_variances,\n",
    "            all_posterior_rgb_means,\n",
    "            all_posterior_rgb_variances,\n",
    "            all_posterior_weights,\n",
    "            all_cluster_assignment,\n",
    "            tr,\n",
    "        )\n",
    "\n",
    "    else:  # One Gibbs sweep consist of updating each latent variable\n",
    "\n",
    "        def update(carry, _):\n",
    "            key, tr = carry\n",
    "            # Gibbs update on cluster assignments\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(gibbs_updates.update_cluster_assignment)(subkey, tr)\n",
    "\n",
    "            # Gibbs update on xy means\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(gibbs_updates.update_xy_mean)(subkey, tr)\n",
    "\n",
    "            # Gibbs update on rgb means\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(gibbs_updates.update_rgb_mean)(subkey, tr)\n",
    "\n",
    "            # Gibbs update on mixture weights\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(gibbs_updates.update_mixture_weight)(subkey, tr)\n",
    "\n",
    "            return (key, tr), None\n",
    "\n",
    "        # Overall inference performs a fixed number of Gibbs sweeps\n",
    "        scan_fn = jax.jit(lambda c, x: update(c, x))\n",
    "        (key, tr), _ = jax.lax.scan(scan_fn, (key, tr), None, length=N_ITER)\n",
    "        return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECORD:\n",
    "    (\n",
    "        all_posterior_xy_means,\n",
    "        all_posterior_xy_variances,\n",
    "        all_posterior_rgb_means,\n",
    "        all_posterior_rgb_variances,\n",
    "        all_posterior_weights,\n",
    "        all_cluster_assignment,\n",
    "        tr,\n",
    "    ) = jax.jit(infer)(image, hypers)\n",
    "else:\n",
    "    tr = jax.jit(infer)(image, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizating Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = animation.create_cluster_visualization(\n",
    "    all_posterior_xy_means,\n",
    "    all_posterior_xy_variances,\n",
    "    all_posterior_weights,\n",
    "    all_posterior_rgb_means,\n",
    "    all_cluster_assignment,\n",
    "    image=image,\n",
    "    num_frames=15,\n",
    "    pixel_sampling=10,  # Sample every 10th pixel\n",
    "    confidence_factor=3.0,  # Scale factor for ellipses\n",
    "    min_weight=0.01,  # Minimum weight threshold for showing clusters\n",
    ")\n",
    "\n",
    "visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: write a visualization of the intermediate steps, and maybe generate more points at each step for better rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_xy = tr.get_choices()[\"blob_model\", \"sigma_xy\"]\n",
    "sigma_rgb = tr.get_choices()[\"blob_model\", \"sigma_rgb\"]\n",
    "xy_mean = tr.get_choices()[\"blob_model\", \"xy_mean\"]\n",
    "rgb_mean = tr.get_choices()[\"blob_model\", \"rgb_mean\"]\n",
    "mixture_weight = tr.get_choices()[\"blob_model\", \"mixture_weight\"]\n",
    "# obs = sigma_xy | sigma_rgb | xy_mean | rgb_mean | mixture_weight\n",
    "obs = (\n",
    "    C[\"blob_model\", \"sigma_xy\"].set(sigma_xy)\n",
    "    | C[\"blob_model\", \"sigma_rgb\"].set(sigma_rgb)\n",
    "    | C[\"blob_model\", \"xy_mean\"].set(xy_mean)\n",
    "    | C[\"blob_model\", \"rgb_mean\"].set(rgb_mean)\n",
    "    | C[\"blob_model\", \"mixture_weight\"].set(mixture_weight)\n",
    ")\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "args = (hypers,)\n",
    "new_tr, _ = jax.jit(model_simple_continuous.model.importance)(subkey, obs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = new_tr.get_choices()[\"likelihood_model\", \"xy\"]\n",
    "rgb = jnp.clip(new_tr.get_choices()[\"likelihood_model\", \"rgb\"], 0, 255)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Generated points\n",
    "ax1.scatter(\n",
    "    xy[:, 0], -xy[:, 1], c=rgb / 255.0, s=1\n",
    ")  # Negate y coordinates to flip vertically\n",
    "ax1.axis(\"equal\")\n",
    "ax1.set_title(\"Generated Points\")\n",
    "ax1.set_xlabel(\"X\")\n",
    "ax1.set_ylabel(\"Y\")\n",
    "\n",
    "# Original image\n",
    "ax2.imshow(image)\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title(\"Original Image\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_squared_deviations(datapoints, cluster_indices, means, n_clusters):\n",
    "    \"\"\"Compute sum of squared deviations from cluster means.\n",
    "\n",
    "    Args:\n",
    "        datapoints: Array of shape (N, D) containing observations\n",
    "        cluster_indices: Array of shape (N,) containing cluster assignments\n",
    "        means: Array of shape (K, D) containing cluster means\n",
    "        n_clusters: Number of clusters K\n",
    "\n",
    "    Returns:\n",
    "        Array of shape (K, D) containing sum of squared deviations per cluster\n",
    "    \"\"\"\n",
    "\n",
    "    def sum_squared_devs(cluster_idx):\n",
    "        # Compute (x - μ)² for all points\n",
    "        diffs = datapoints - means[cluster_idx]\n",
    "        squared_diffs = jnp.sum(\n",
    "            diffs**2, axis=1, keepdims=True\n",
    "        )  # Sum across dimensions first\n",
    "\n",
    "        # Use where to mask points not in this cluster\n",
    "        masked_diffs = jnp.where(\n",
    "            (cluster_indices == cluster_idx)[:, None], squared_diffs, 0.0\n",
    "        )\n",
    "\n",
    "        # Sum over all points\n",
    "        return jnp.sum(masked_diffs, axis=0)\n",
    "\n",
    "    # Compute for each cluster\n",
    "    deviations = jax.vmap(sum_squared_devs)(jnp.arange(n_clusters))\n",
    "    return deviations\n",
    "\n",
    "\n",
    "# Test case\n",
    "datapoints = jnp.array([\n",
    "    [1.0, 1.0],  # point 0: cluster 0\n",
    "    [2.0, 2.0],  # point 1: cluster 0\n",
    "    [10.0, 10.0],  # point 2: cluster 1\n",
    "    [11.0, 11.0],  # point 3: cluster 1\n",
    "])\n",
    "cluster_indices = jnp.array([0, 0, 1, 1])\n",
    "means = jnp.array([[1.5, 1.5], [10.5, 10.5]])\n",
    "n_clusters = 2\n",
    "\n",
    "# Let's debug cluster 0 manually:\n",
    "cluster_idx = 0\n",
    "diffs = datapoints - means[cluster_idx]\n",
    "print(\"Diffs for cluster 0:\")\n",
    "print(diffs)\n",
    "\n",
    "squared_diffs = diffs**2\n",
    "print(\"\\nSquared diffs:\")\n",
    "print(squared_diffs)\n",
    "\n",
    "mask = (cluster_indices == cluster_idx)[:, None]\n",
    "print(\"\\nMask:\")\n",
    "print(mask)\n",
    "\n",
    "masked_diffs = jnp.where(mask, squared_diffs, 0.0)\n",
    "print(\"\\nMasked diffs:\")\n",
    "print(masked_diffs)\n",
    "\n",
    "sum_result = jnp.sum(masked_diffs, axis=0)\n",
    "print(\"\\nSum result:\")\n",
    "print(sum_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
