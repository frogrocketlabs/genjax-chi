{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows a simple model for clustering a 2D image into different components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import model_simple_continuous\n",
    "from scipy import misc\n",
    "\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import pretty\n",
    "\n",
    "pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing to sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = misc.face()\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "H, W, _ = image.shape\n",
    "\n",
    "image.shape\n",
    "hypers = model_simple_continuous.Hyperparams(\n",
    "    a_x=1.0,\n",
    "    b_x=1.0,\n",
    "    a_y=1.0,\n",
    "    b_y=1.0,\n",
    "    mu_x=0.0,\n",
    "    mu_y=0.0,\n",
    "    a_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    b_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    alpha=1.0,\n",
    "    sigma_xy=jnp.array([1.0, 1.0]),\n",
    "    sigma_rgb=jnp.array([1.0, 1.0, 1.0]),\n",
    "    n_blobs=100,\n",
    "    H=H,\n",
    "    W=W,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "tr = model_simple_continuous.model.simulate(subkey, (hypers,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_image = jnp.concatenate(\n",
    "    (jnp.indices((H, W)).reshape(H * W, 2), image.reshape(H * W, 3)), axis=1\n",
    ")\n",
    "\n",
    "xy, rgb = flattened_image[:, :2], flattened_image[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial trace for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "obs = C[\"likelihood_model\", \"xy\"].set(xy) ^ C[\"likelihood_model\", \"rgb\"].set(rgb)\n",
    "\n",
    "tr = model_simple_continuous.model.importance(subkey, obs, (hypers,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do inference via exact block-Gibbs, using the fact that the model is defined using conjugate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_update_mvnormal_with_known_cov(\n",
    "    prior_mean,  # (D,)\n",
    "    prior_cov,  # (D, D)\n",
    "    obs_cov,  # (D, D)\n",
    "    obs,  # (M, D)\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the posterior mean and covariance for the mean\n",
    "    of a multivariate normal distribution with known covariance.\n",
    "    That is, given\n",
    "      mu ~ Normal(prior_mean, prior_cov),\n",
    "      obs_i ~ Normal(mu, obs_cov) for i = 0, 1, ..., M-1,\n",
    "    this function returns (post_mean, post_cov) where\n",
    "      P(mu | obs) = Normal(post_mean, post_cov).\n",
    "    \"\"\"\n",
    "    M = obs.shape[0]\n",
    "    post_cov = jnp.linalg.inv(jnp.linalg.inv(prior_cov) + M * jnp.linalg.inv(obs_cov))\n",
    "    obsmean = jnp.sum(obs) / M\n",
    "    post_mean = post_cov @ (\n",
    "        jnp.linalg.inv(prior_cov) @ prior_mean + M * jnp.linalg.inv(obs_cov) @ obsmean\n",
    "    )\n",
    "    return jnp.where(M > 0, post_mean, prior_mean), jnp.where(\n",
    "        M > 0, post_cov, prior_cov\n",
    "    )\n",
    "\n",
    "\n",
    "def dirichlet_categorical_update(key, associations, n_clusters, alpha):\n",
    "    \"\"\"Returns (categorical_vector, metadata_dict).\"\"\"\n",
    "\n",
    "    def get_assoc_count(cluster_idx):\n",
    "        masked_relevant_datapoint_indices = tiling.relevant_datapoints_for_blob(\n",
    "            cluster_idx\n",
    "        )\n",
    "        relevant_associations = associations[masked_relevant_datapoint_indices.value]\n",
    "        return jnp.sum(\n",
    "            jnp.logical_and(\n",
    "                masked_relevant_datapoint_indices.flag,\n",
    "                relevant_associations == cluster_idx,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    assoc_counts = jax.vmap(get_assoc_count)(jnp.arange(n_clusters))\n",
    "    prior_alpha = alpha\n",
    "    post_alpha = prior_alpha + assoc_counts\n",
    "    return dirichlet(post_alpha)(key), {}\n",
    "\n",
    "\n",
    "def conjugate_dirichlet_categorical(\n",
    "    key, associations, n_clusters, alpha, λ=model_simple_continuous.GAMMA_RATE_PARAMETER\n",
    "):\n",
    "    \"\"\"\n",
    "    Conjugate update for the case where we have\n",
    "        X_i ~ Gamma(alpha_i / n, lambda) for i = 1, 2, ..., n;\n",
    "        X_0 := sum_i X_i\n",
    "        p := [X_1, X_2, ..., X_n] / X_0\n",
    "        Y_i ~ Categorical(p) for i = 1, 2, ..., m.\n",
    "\n",
    "    Here, `n_clusters` is `n`, `associations` is `Y`,\n",
    "    and `alpha_vec_for_gamma_distributions[i-1]` is `alpha_i`.\n",
    "\n",
    "    Returns (mixture_weights, metadata), where `mixture_weights`\n",
    "    is the same thing as the vector `[X_1, X_2, ..., X_n]`.\n",
    "    \"\"\"\n",
    "    ## Derivation of this update:\n",
    "    # With notation as the above, it turns out\n",
    "    # X_0 ~ Gamma(alpha.sum(), lambda),\n",
    "    # p ~ Dirichlet(alpha_1, alpha_2, ..., alpha_n),\n",
    "    # and X_0 and p are independent.\n",
    "    # Thus, the posterior on (X_0, p) is\n",
    "    # p ~ dirichlet_categorical_posterior(alpha, n, assoc_counts);\n",
    "    # X_0 ~ gamma(alpha.sum(), lambda). # Ie. same as the prior.\n",
    "    k1, k2 = split(key)\n",
    "    posterior_pvec, _ = dirichlet_categorical_update(\n",
    "        k1, associations, n_clusters, alpha\n",
    "    )\n",
    "    total = gamma(alpha.sum(), λ)(k2)\n",
    "    return posterior_pvec * total, {}\n",
    "\n",
    "\n",
    "# one option in the mean time is to replace inverse_gamma in the model by a categorical with 64 values.\n",
    "def conjugate_update_mean_normal_inverse_gamma():\n",
    "    return None\n",
    "\n",
    "\n",
    "def conjugate_update_sigma_normal_inverse_gamma():\n",
    "    return None\n",
    "\n",
    "\n",
    "def conjugate_discrete_enumeration():\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_xy_mean(xy_mean, xy_mean_blanket):\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_xy_sigma(xy_sigma, xy_sigma_blanket):\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_rgb_mean(rgb_mean, rgb_mean_blanket):\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_rgb_sigma(rgb_sigma, rgb_sigma_blanket):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write discretized model\n",
    "### exact inference on discretized model\n",
    "### exact Gibbs move on discretized model\n",
    "### exact Gibbs for continuous model\n",
    "### test exact Gibbs\n",
    "### update for cont model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
