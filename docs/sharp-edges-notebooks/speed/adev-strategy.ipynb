{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: test batching semantics and some other potential ADEV optims manually on some basic examples to see if they could be worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.923923e+21\n",
      "\n",
      "-9.923923e+21\n",
      "79.5 ms ± 567 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import jit\n",
    "\n",
    "def g(b, dp, dr):\n",
    "    return jax.lax.cond(b, lambda x: x, lambda x: 1.0 - x, dr) * dp\n",
    "\n",
    "def dkont(x):\n",
    "    return x[0]\n",
    "\n",
    "# v1: using array inplace updates\n",
    "def f1(dp_list, dr_init):\n",
    "    k = 2   # here it's just 2 because it's a flip_enum\n",
    "    n = len(dp_list)\n",
    "    array = jnp.zeros(k**n)\n",
    "    array = array.at[0].set(dr_init)\n",
    "\n",
    "    # going down the tree, breadth first\n",
    "    for i in range(n):   \n",
    "        for j in range(2**i):\n",
    "            array = array.at[2**i+j].set(g(jnp.mod(1+j, 2), dp_list[i], array[(2**i+j-1)//2])) # 1+j mod 2 is a hacky way to encode True/False\n",
    "  \n",
    "    array2 = jnp.zeros(k**n)\n",
    "    # only need the second half of array as these are the final values passed to the final continuation dkont\n",
    "\n",
    "    # jax.debug.print(\"array: {x}\", x=array)\n",
    "    mid = 2**(n-1)\t\n",
    "    # jax.debug.print(\"mid: {x}\", x=mid)\n",
    "    # jax.debug.print(\"array2: {x}\", x=array2)\n",
    "    array2 = array2.at[:mid].set(dkont(array[mid:]))\n",
    "    # jax.debug.print(\"array2: {x}\", x=array2)\n",
    "    for i in range(n-1,-1,-1):  # going up the tree, breadth first\n",
    "        for j in range(2**i):\n",
    "            array2 = array2.at[2**i+j].set(array2[2*(2**i+j)] * dp_list[n-i-1] + array2[2*(2**i+j)+1] * (1.0 - dp_list[n-i-1])) # still computing in dual-number land\n",
    "            \n",
    "    return array2[0]\n",
    "\n",
    "# v2: same as v1 but using more JAX primitives\n",
    "def f2(dp_list, dr_init):\n",
    "    k = 2  \n",
    "    n = len(dp_list)\n",
    "    array = jnp.zeros(k**n)\n",
    "    array = array.at[0].set(dr_init)\n",
    "\n",
    "    array = jax.lax.fori_loop(0, n, lambda i, x: jax.lax.fori_loop(0, 2**i, lambda j, y: y.at[2**i+j].set(g(jnp.mod(1+j, 2), dp_list[i], y[(2**i+j-1)//2])), x), array)\n",
    "  \n",
    "    array2 = jnp.zeros(k**n)\n",
    "\n",
    "    mid = 2**(n-1)\t\n",
    "    array2 = array2.at[:mid].set(dkont(array[mid:]))\n",
    "            \n",
    "    array2 = jax.lax.fori_loop(0, n, lambda i, x: jax.lax.fori_loop(0, 2**(n-1-i), lambda j, y: y.at[2**(n-1-i)+j].set(y[2*(2**(n-1-i)+j)] * dp_list[i] + y[2*(2**(n-1-i)+j)+1] * (1.0 - dp_list[i])), x), array2)\n",
    "    \n",
    "    return array2[0]\n",
    "\n",
    "# v3: using jax.lax.dynamic_slice\n",
    "def f3(dp_list, dr_init):\n",
    "    k = 2  \n",
    "    n = len(dp_list)\n",
    "    array = jnp.zeros(k**n)\n",
    "    array = array.at[0].set(dr_init)\n",
    "\n",
    "    array = jax.lax.fori_loop(0, n, \n",
    "        lambda i, x: jax.lax.fori_loop(0, 2**i, lambda j, y: y.at[2**i+j].set(g(jnp.mod(1+j, 2), dp_list[i], y[(2**i+j-1)//2])), x), array)\n",
    "    \n",
    "    # same as v2 but using dynamic_slice, using only one for loop\n",
    "    # array = jax.lax.fori_loop(0, n, lambda i, x: jax.lax.dynamic_slice(x, [2**(n-1-i), 2**(i+1)], [2**(n-1-i), 0]), array)\n",
    "\n",
    "    array2 = jnp.zeros(k**n)\n",
    "\n",
    "    mid = 2**(n-1)\t\n",
    "    array2 = array2.at[:mid].set(dkont(array[mid:]))\n",
    "            \n",
    "    array2 = jax.lax.fori_loop(0, n, lambda i, x: jax.lax.fori_loop(0, 2**(n-1-i), lambda j, y: y.at[2**(n-1-i)+j].set(y[2*(2**(n-1-i)+j)] * dp_list[i] + y[2*(2**(n-1-i)+j)+1] * (1.0 - dp_list[i])), x), array2)\n",
    "    \n",
    "    return array2[0]\n",
    "\n",
    "# v4: using naive parallelism\n",
    "# hmmm, doesn't actually seem easier to write than v1\n",
    "def f3(dp_list, dr_init):\n",
    "    k = 2\n",
    "    n = len(dp_list)\n",
    "    array = jnp.full(k**n, dr_init)\n",
    "    return array\n",
    "    \n",
    "# Testing\n",
    "dp_list = jnp.arange(1, 25)\n",
    "dr_init = 1.0\n",
    "# print(f1(dp_list, dr_init))\n",
    "print(f2(dp_list, dr_init))\n",
    "print()\n",
    "# jitted1 = jit(f1)\n",
    "# print(jitted1(dp_list, dr_init))\n",
    "jitted2 = jit(f2)\n",
    "print(jitted2(dp_list, dr_init))\n",
    "\n",
    "# %timeit jitted1(dp_list, dr_init)\n",
    "%timeit jitted2(dp_list, dr_init)\n",
    "# TODO: this is somehow very slow on GPU even though the doc says that the updates should be in-place as the function is jitted\n",
    "# takes 400ms for len(dp_list) = 14 on GPU, and compile time is also not constant\n",
    "# and growing rapidly with len(dp_list).\n",
    "\n",
    "# Update from Matin: need to replace inner for_loop with jax.lax.dynamic_slice and dynamic_update_slice and a vmap. also jitting tree-map should be doing something similar on its own, at the price of a possibly much higher compile time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
