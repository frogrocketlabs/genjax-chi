{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: dirichlet mixture model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now see some of the ingredients in action in a simple but more realistic setting and write a dirichlet mixture model in GenJAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to cluster datapoints on the real line.\n",
    "To do so, we model a fixed number of clusters, each as a 1D-Gaussian with fixed variance, and we want to infer their means.\n",
    "\n",
    "In more details, the model of the world postulates a fixed number of 1D Gaussians.\n",
    "Each Gaussian is assigned a weight to represent the proportion of the number of points assigned to each cluster.\n",
    "Finally, each datapoint belongs to a cluster, separated proportionally to cluster weights.\n",
    "\n",
    "We turn this into a generative model as follows.\n",
    "We have a fix prior mean and variance for where the clusters centres might be.\n",
    "We sample a mean for each cluster. \n",
    "We sample the cluster weights.\n",
    "For each datapoint, \n",
    "- we sample a cluster assignment for that data point proportional to the cluster weights\n",
    "- we sampled the TODO: add explanation for what's going on and what we will do and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import categorical, dirichlet, gen, normal, pretty\n",
    "from genjax._src.core.pytree import Const, Pytree\n",
    "\n",
    "pretty()\n",
    "key = jax.random.key(0)\n",
    "\n",
    "# Hyper parameters\n",
    "PRIOR_MEAN = 10.0\n",
    "PRIOR_VARIANCE = 3.0\n",
    "OBS_VARIANCE = 1.0\n",
    "ALPHA = 1.0\n",
    "N_DATAPOINTS = 1000\n",
    "N_CLUSTERS = 10\n",
    "N_ITER = 1000\n",
    "\n",
    "# Debugging mode\n",
    "DEBUG = True\n",
    "\n",
    "\n",
    "@Pytree.dataclass\n",
    "class Cluster(Pytree):\n",
    "    mean: float\n",
    "\n",
    "\n",
    "@gen\n",
    "def generate_cluster(mean, var):\n",
    "    cluster_mean = normal(mean, var) @ \"mean\"\n",
    "    return Cluster(cluster_mean)\n",
    "\n",
    "\n",
    "@gen\n",
    "def generate_cluster_weight(alphas):\n",
    "    probs = dirichlet(alphas) @ \"probs\"\n",
    "    return probs\n",
    "\n",
    "\n",
    "@gen\n",
    "def generate_datapoint(probs, clusters):\n",
    "    idx = categorical(jnp.log(probs)) @ \"idx\"\n",
    "    obs = normal(clusters.mean[idx], OBS_VARIANCE) @ \"obs\"\n",
    "    return obs\n",
    "\n",
    "\n",
    "@gen\n",
    "def generate_data(n_clusters: Const[int], n_datapoints: Const[int], alpha: float):\n",
    "    clusters = (\n",
    "        generate_cluster.repeat(n=n_clusters.unwrap())(PRIOR_MEAN, PRIOR_VARIANCE)\n",
    "        @ \"clusters\"\n",
    "    )\n",
    "\n",
    "    probs = generate_cluster_weight.inline(\n",
    "        alpha / n_clusters.unwrap() * jnp.ones(n_clusters.unwrap())\n",
    "    )\n",
    "\n",
    "    datapoints = (\n",
    "        generate_datapoint.repeat(n=n_datapoints.unwrap())(probs, clusters)\n",
    "        @ \"datapoints\"\n",
    "    )\n",
    "\n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = C[\"datapoints\", \"obs\"].set(\n",
    "    jnp.concatenate([\n",
    "        jax.random.uniform(jax.random.key(i), shape=(int(N_DATAPOINTS / N_CLUSTERS),))\n",
    "        + 2 * i\n",
    "        for i in range(N_CLUSTERS)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(datapoints):\n",
    "    key = jax.random.key(32421)\n",
    "    args = (Const(N_CLUSTERS), Const(N_DATAPOINTS), ALPHA)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    tr, _ = generate_data.importance(subkey, datapoints, args)\n",
    "\n",
    "    if DEBUG:\n",
    "        all_posterior_means = [tr.get_choices()[\"clusters\", \"mean\"]]\n",
    "        all_posterior_weights = [tr.get_choices()[\"probs\"]]\n",
    "        all_cluster_assignment = [tr.get_choices()[\"datapoints\", \"idx\"]]\n",
    "\n",
    "        jax.debug.print(\"Initial means: {v}\", v=all_posterior_means[0])\n",
    "        jax.debug.print(\"Initial weights: {v}\", v=all_posterior_weights[0])\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        tr = jax.jit(update_cluster_means)(subkey, tr)\n",
    "        all_posterior_means.append(tr.get_choices()[\"clusters\", \"mean\"])\n",
    "\n",
    "        jax.debug.print(\"Initial means V2: {v}\", v=tr.get_choices()[\"clusters\", \"mean\"])\n",
    "\n",
    "        # Gibbs update on `(\"datapoints\", i, \"idx\")` for each `i`, in parallel\n",
    "        key, subkey = jax.random.split(key)\n",
    "        tr = jax.jit(update_datapoint_assignment)(subkey, tr)\n",
    "        all_cluster_assignment.append(tr.get_choices()[\"datapoints\", \"idx\"])\n",
    "\n",
    "        jax.debug.print(\"Initial means V3: {v}\", v=tr.get_choices()[\"clusters\", \"mean\"])\n",
    "\n",
    "        # Gibbs update on `probs`\n",
    "        key, subkey = jax.random.split(key)\n",
    "        tr = jax.jit(update_cluster_weights)(subkey, tr)\n",
    "        all_posterior_weights.append(tr.get_choices()[\"probs\"])\n",
    "\n",
    "        jax.debug.print(\"Initial means V4: {v}\", v=tr.get_choices()[\"clusters\", \"mean\"])\n",
    "\n",
    "        for _ in range(N_ITER):\n",
    "            # Gibbs update on `(\"clusters\", i, \"mean\")` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_cluster_means)(subkey, tr)\n",
    "            all_posterior_means.append(tr.get_choices()[\"clusters\", \"mean\"])\n",
    "\n",
    "            # # Gibbs update on `(\"datapoints\", i, \"idx\")` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_datapoint_assignment)(subkey, tr)\n",
    "            all_cluster_assignment.append(tr.get_choices()[\"datapoints\", \"idx\"])\n",
    "\n",
    "            # # Gibbs update on `probs`\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_cluster_weights)(subkey, tr)\n",
    "            all_posterior_weights.append(tr.get_choices()[\"probs\"])\n",
    "\n",
    "        return all_posterior_means, all_posterior_weights, all_cluster_assignment, tr\n",
    "\n",
    "    else:\n",
    "\n",
    "        def update(carry, _):\n",
    "            key, tr = carry\n",
    "            # Gibbs update on `(\"clusters\", i, \"mean\")` for each i, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_cluster_means)(subkey, tr)\n",
    "\n",
    "            # Gibbs update on `(\"datapoints\", i, \"idx\")` for each `i`, in parallel\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_datapoint_assignment)(subkey, tr)\n",
    "\n",
    "            # Gibbs update on `probs`\n",
    "            key, subkey = jax.random.split(key)\n",
    "            tr = jax.jit(update_cluster_weights)(subkey, tr)\n",
    "            return (key, tr), None\n",
    "\n",
    "        (key, tr), _ = jax.lax.scan(update, (key, tr), None, length=N_ITER)\n",
    "        return tr\n",
    "\n",
    "\n",
    "def update_cluster_means(key, trace):\n",
    "    # We can update each cluster in parallel\n",
    "    # For each cluster, we find the datapoints in that cluster and compute their mean\n",
    "    datapoint_indexes = trace.get_choices()[\"datapoints\", \"idx\"]\n",
    "    datapoints = trace.get_choices()[\"datapoints\", \"obs\"]\n",
    "    n_clusters = trace.get_args()[0].unwrap()\n",
    "    current_means = trace.get_choices()[\"clusters\", \"mean\"]\n",
    "\n",
    "    # Count number of points per cluster\n",
    "    category_counts = jnp.bincount(\n",
    "        trace.get_choices()[\"datapoints\", \"idx\"],\n",
    "        length=n_clusters,\n",
    "        minlength=n_clusters,\n",
    "    )\n",
    "\n",
    "    # Will contain some NaN due to clusters having no datapoint\n",
    "    cluster_means = (\n",
    "        jax.vmap(\n",
    "            lambda i: jnp.sum(jnp.where(datapoint_indexes == i, datapoints, 0)),\n",
    "            in_axes=(0),\n",
    "            out_axes=(0),\n",
    "        )(jnp.arange(n_clusters))\n",
    "        / category_counts\n",
    "    )\n",
    "\n",
    "    # Conjugate update for Normal-iid-Normal distribution\n",
    "    # See https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture5.pdf\n",
    "    posterior_means = (\n",
    "        PRIOR_VARIANCE\n",
    "        / (PRIOR_VARIANCE + OBS_VARIANCE / category_counts)\n",
    "        * cluster_means\n",
    "        + OBS_VARIANCE / (PRIOR_VARIANCE + OBS_VARIANCE / category_counts) * PRIOR_MEAN\n",
    "    )\n",
    "\n",
    "    posterior_variances = 1 / (1 / PRIOR_VARIANCE + category_counts / OBS_VARIANCE)\n",
    "\n",
    "    # Gibbs resampling of cluster means\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_means = (\n",
    "        generate_cluster.vmap()\n",
    "        .simulate(key, (posterior_means, posterior_variances))\n",
    "        .get_choices()[\"mean\"]\n",
    "    )\n",
    "\n",
    "    # Remove the sampled Nan due to clusters having no datapoint and pick previous mean in that case, i.e. no Gibbs update for them\n",
    "    chosen_means = jnp.where(category_counts == 0, current_means, new_means)\n",
    "\n",
    "    if DEBUG:\n",
    "        jax.debug.print(\"Category counts: {v}\", v=category_counts)\n",
    "        jax.debug.print(\"Current means: {v}\", v=cluster_means)\n",
    "        jax.debug.print(\"Posterior means: {v}\", v=posterior_means)\n",
    "        posterior_variances = 1 / (1 / PRIOR_VARIANCE + category_counts / OBS_VARIANCE)\n",
    "        jax.debug.print(fmt=\"Posterior variance: {v}\", v=posterior_variances)\n",
    "        jax.debug.print(\"Resampled means: {v}\", v=new_means)\n",
    "        jax.debug.print(\"Chosen means: {v}\", v=chosen_means)\n",
    "\n",
    "    argdiffs = genjax.Diff.no_change(trace.args)\n",
    "    new_trace, _, _, _ = trace.update(\n",
    "        subkey, C[\"clusters\", \"mean\"].set(chosen_means), argdiffs\n",
    "    )\n",
    "    return new_trace\n",
    "\n",
    "\n",
    "def update_datapoint_assignment(key, trace):\n",
    "    # We want to update the index for each datapoint, in parallel.\n",
    "    # It means we want to resample the i, but instead of being from the prior\n",
    "    # P(i | probs), we do it from the local posterior P(i | probs, xs).\n",
    "    # We need to do it for all addresses [\"datapoints\", \"idx\", i],\n",
    "    # and as these are independent (when conditioned on the rest)\n",
    "    # we can resample them in parallel.\n",
    "\n",
    "    # Conjugate update for a categorical is just exact posterior via enumeration\n",
    "    # P(x | y ) = P(x, y) \\ sum_x P(x, y).\n",
    "    # P(x | y1, y2) = P(x | y1)\n",
    "    # Sampling from Categorical(P(x = 1 | y ), P(x = 2 | y), ...) is the same as\n",
    "    # sampling from Categorical(P(x = 1, y), P(x = 2, y))\n",
    "    # as the weights need not be normalized\n",
    "    def compute_local_density(x, i):\n",
    "        datapoint_mean = trace.get_choices()[\"datapoints\", \"obs\", x]\n",
    "        chm = C[\"obs\"].set(datapoint_mean).at[\"idx\"].set(i)\n",
    "        clusters = Cluster(trace.get_choices()[\"clusters\", \"mean\"])\n",
    "        probs = trace.get_choices()[\"probs\"]\n",
    "        args = (probs, clusters)\n",
    "        model_logpdf, _ = generate_datapoint.assess(chm, args)\n",
    "        return model_logpdf\n",
    "\n",
    "    n_clusters = trace.get_args()[0].unwrap()\n",
    "    n_datapoints = trace.get_args()[1].unwrap()\n",
    "    local_densities = jax.vmap(\n",
    "        lambda x: jax.vmap(lambda i: compute_local_density(x, i))(\n",
    "            jnp.arange(n_clusters)\n",
    "        )\n",
    "    )(jnp.arange(n_datapoints))\n",
    "\n",
    "    # Conjugate update by sampling from posterior categorical\n",
    "    # Note: I think I could've used something like\n",
    "    # generate_datapoint.vmap().importance which would perhaps\n",
    "    # work more generally but would definitely be slower here\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_datapoint_indexes = (\n",
    "        genjax.categorical.vmap().simulate(key, (local_densities,)).get_choices()\n",
    "    )\n",
    "    # Gibbs resampling of datapoint assignment to clusters\n",
    "    argdiffs = genjax.Diff.no_change(trace.args)\n",
    "    new_trace, _, _, _ = trace.update(\n",
    "        subkey, C[\"datapoints\", \"idx\"].set(new_datapoint_indexes), argdiffs\n",
    "    )\n",
    "    return new_trace\n",
    "\n",
    "\n",
    "def update_cluster_weights(key, trace):\n",
    "    # Count number of points per cluster\n",
    "    n_clusters = trace.get_args()[0].unwrap()\n",
    "    category_counts = jnp.bincount(\n",
    "        trace.get_choices()[\"datapoints\", \"idx\"],\n",
    "        length=n_clusters,\n",
    "        minlength=n_clusters,\n",
    "    )\n",
    "\n",
    "    # Conjugate update for Dirichlet distribution\n",
    "    # See https://en.wikipedia.org/wiki/Dirichlet_distribution#Conjugate_to_categorical_or_multinomial\n",
    "    new_alpha = ALPHA / n_clusters * jnp.ones(n_clusters) + category_counts\n",
    "\n",
    "    # Gibbs resampling of cluster weights\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_probs = generate_cluster_weight.simulate(key, (new_alpha,)).get_retval()\n",
    "\n",
    "    if DEBUG:\n",
    "        jax.debug.print(fmt=\"Category counts: {v}\", v=category_counts)\n",
    "        jax.debug.print(fmt=\"New alpha: {v}\", v=new_alpha)\n",
    "        jax.debug.print(fmt=\"New probs: {v}\", v=new_probs)\n",
    "    argdiffs = genjax.Diff.no_change(trace.args)\n",
    "    new_trace, _, _, _ = trace.update(subkey, C[\"probs\"].set(new_probs), argdiffs)\n",
    "    return new_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    (\n",
    "        all_posterior_means,\n",
    "        all_posterior_weights,\n",
    "        all_cluster_assignment,\n",
    "        posterior_trace,\n",
    "    ) = infer(datapoints)\n",
    "else:\n",
    "    posterior_trace = infer(datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create plot for a given index\n",
    "def create_plot(idx):\n",
    "    datapoint = datapoints[\"datapoints\", \"obs\"]\n",
    "    posterior_means = all_posterior_means[idx]\n",
    "    posterior_weights = all_posterior_weights[idx]\n",
    "    cluster_assignment = all_cluster_assignment[idx]\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "    # Plot datapoints colored by cluster assignment and posterior means together\n",
    "    for i in range(len(posterior_means)):\n",
    "        # Only plot points assigned to this cluster\n",
    "        mask = cluster_assignment == i\n",
    "        if not jnp.any(mask):  # Skip if no points assigned to this cluster\n",
    "            continue\n",
    "\n",
    "        ax.scatter(\n",
    "            datapoint[mask],\n",
    "            jnp.zeros_like(datapoint)[mask],\n",
    "            color=f\"C{i}\",\n",
    "            alpha=0.5,\n",
    "            s=20,\n",
    "        )\n",
    "\n",
    "        # Plot posterior means with size proportional to weights\n",
    "        weight = posterior_weights[i]  # Get current weight for this iteration\n",
    "        ax.scatter(\n",
    "            posterior_means[i],\n",
    "            0,\n",
    "            color=f\"C{i}\",\n",
    "            marker=\"*\",\n",
    "            s=100 + weight * 600,  # Use current weight for size\n",
    "            alpha=1,\n",
    "            label=f\"Cluster {i + 1} (Prob: {weight:.6f})\",  # Use current weight for label\n",
    "        )\n",
    "\n",
    "        # Plot standard deviation of the Gaussian means\n",
    "        ax.errorbar(\n",
    "            posterior_means[i],\n",
    "            0,\n",
    "            xerr=jnp.sqrt(PRIOR_VARIANCE),\n",
    "            fmt=\"o\",\n",
    "            color=f\"C{i}\",\n",
    "            capsize=5,\n",
    "        )\n",
    "\n",
    "    ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "    ax.set_title(f\"Iteration {idx}\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "NUM_FRAMES = 50\n",
    "\n",
    "# Create animation\n",
    "frames = []\n",
    "for i in range(NUM_FRAMES):\n",
    "    fig = create_plot(int(N_ITER / NUM_FRAMES * i))\n",
    "    # Convert figure to image array\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(\n",
    "        fig.canvas.buffer_rgba(), dtype=np.uint8\n",
    "    )  # Updated to use buffer_rgba\n",
    "    image = image.reshape(\n",
    "        fig.canvas.get_width_height()[::-1] + (4,)\n",
    "    )  # Note: buffer_rgba returns RGBA\n",
    "    frames.append(image[:, :, :3])  # Convert RGBA to RGB by dropping alpha channel\n",
    "    plt.close(fig)\n",
    "\n",
    "# Create animation from frames\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "from matplotlib import animation\n",
    "\n",
    "ani = animation.ArtistAnimation(\n",
    "    fig,\n",
    "    [[plt.imshow(frame)] for frame in frames],\n",
    "    interval=1000,  # 1 second between frames\n",
    "    blit=True,\n",
    ")\n",
    "\n",
    "# Display animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example vectors of size 10\n",
    "category_counts = jnp.array([0, 0, 0, 0, 0, 4, 0, 2, 1, 7])\n",
    "current_means = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])\n",
    "new_means = jnp.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5])\n",
    "\n",
    "# Where category_counts is 0, use current_means, otherwise use new_means\n",
    "chosen_means = jnp.where(category_counts == 0, current_means, new_means)\n",
    "chosen_means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
