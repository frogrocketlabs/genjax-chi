{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Incremental computation via Update\n",
    "subtitle: How to not compute log pdfs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax import gen\n",
    "\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing inference with iterative algorithms like MCMC, we often need to make small adjustments to the choice map.\n",
    "\n",
    "For instance, consider the following generative model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen\n",
    "def generate_datum(x, prob_outlier, noise, slope, intercept):\n",
    "    b = genjax.flip(prob_outlier) @ \"is_outlier\"\n",
    "    mu, std = jax.lax.cond(\n",
    "        b, lambda _: (0.0, 10.0), lambda _: (slope * x + intercept, noise), None\n",
    "    )\n",
    "    y = genjax.normal(mu, std) @ \"y\"\n",
    "    return y\n",
    "\n",
    "\n",
    "generate_data = generate_datum.vmap(in_axes=(0, None, None, None, None))\n",
    "\n",
    "\n",
    "@gen\n",
    "def model(xs):\n",
    "    slope = genjax.normal(0.0, 2.0) @ \"slope\"\n",
    "    intercept = genjax.normal(0.0, 2.0) @ \"intercept\"\n",
    "    noise = genjax.gamma(0.0, 1.0) @ \"noise\"\n",
    "    prob_outlier = genjax.beta(1.0, 1.0) @ \"prob_outlier\"\n",
    "    ys = generate_data(xs, prob_outlier, noise, slope, intercept) @ \"data\"\n",
    "    return ys\n",
    "\n",
    "\n",
    "def make_observations(ys):\n",
    "    range = jnp.arange(ys.shape[0])\n",
    "    obs = jax.vmap(lambda idx: C[\"data\", idx, \"y\"].set(ys[idx]))(range)\n",
    "    return obs\n",
    "\n",
    "\n",
    "@gen\n",
    "def is_outlier_proposal(trace):\n",
    "    # TODO: problem of accessing this as I get a vmapped trace as input which I don't assume here, so I need the right index etc.\n",
    "    is_outlier = trace.get_choices()[\"is_outlier\"]\n",
    "    prob_outlier = jax.lax.cond(is_outlier, lambda _: 0.0, lambda _: 1.0, None)\n",
    "    outlier_proposal = genjax.flip(prob_outlier) @ \"is_outlier\"\n",
    "    return outlier_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write an inference using MH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_iters = 1000\n",
    "\n",
    "\n",
    "def metropolis_hastings_move(key, model, proposal, trace, observations):\n",
    "    model_args = trace.get_args()\n",
    "    argdiffs = genjax.Diff.tree_diff_no_change(model_args)\n",
    "    proposal_args_forward = (trace,)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    fwd_choices, fwd_weight, _ = proposal.propose(key, proposal_args_forward)\n",
    "    new_trace, weight, _, discard = model.update(subkey, trace, fwd_choices, argdiffs)\n",
    "    proposal_args_backward = (new_trace,)\n",
    "    bwd_weight, _ = proposal.assess(discard, proposal_args_backward)\n",
    "    α = weight - fwd_weight + bwd_weight\n",
    "    key, subkey = jax.random.split(key)\n",
    "    ret_trace = jax.lax.cond(\n",
    "        jnp.log(jax.random.uniform(subkey)) < α, lambda: new_trace, lambda: trace\n",
    "    )\n",
    "    return ret_trace\n",
    "\n",
    "\n",
    "def inference_program_1(key, xs, ys):\n",
    "    constraints = make_observations(ys)\n",
    "    # TODO: should I use generate here?\n",
    "    trace, _ = model.importance(key, constraints, (xs,))\n",
    "\n",
    "    len = xs.shape[0]\n",
    "    for i in range(N_iters):\n",
    "        trace = metropolis_hastings_move(\n",
    "            key, model, is_outlier_proposal.repeat(n=len), trace, constraints\n",
    "        )\n",
    "\n",
    "    return trace\n",
    "\n",
    "\n",
    "# testing\n",
    "key, subkey = jax.random.split(key)\n",
    "xs = jnp.linspace(0, 10, 100)\n",
    "ys = (\n",
    "    generate_datum.vmap(in_axes=(0, None, None, None, None))\n",
    "    .simulate(key, (xs, 0.1, 1.0, 1.0, 1.0))\n",
    "    .get_retval()\n",
    ")\n",
    "key, subkey = jax.random.split(key)\n",
    "inference_program_1(subkey, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to do it using the built-in update and see if there's a speedup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
